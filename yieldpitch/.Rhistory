smalldose <- ToothGrowth[which(ToothGrowth$dose==.5)]
largedose <- subset(ToothGrowth, dose == 2)
meddose <- subset(ToothGrowth, dose == 1)
largedose <- subset(ToothGrowth, dose == 2)
#t-tests
t.test(len ~ dose, paired = F, var.equal = F, data = smalldose)
t.test(len ~ dose, paired = F, var.equal = F, data = meddose)
t.test(len ~ dose, paired = F, var.equal = F, data = largedose)
smalldose <- subset(ToothGrowth, dose == .5)
meddose <- subset(ToothGrowth, dose == 1)
largedose <- subset(ToothGrowth, dose == 2)
#t-tests
t.test(len ~ dose, paired = F, var.equal = F, data = smalldose)
t.test(len ~ dose, paired = F, var.equal = F, data = meddose)
t.test(len ~ dose, paired = F, var.equal = F, data = largedose)
dose05 <- subset(data, data$dose==.5, select= c(len, supp))
dose1 <- subset(data, data$dose==1, select= c(len, supp))
dose2 <- subset(data, data$dose==2, select= c(len, supp))
#t-tests
#.5 vs 1
d05vsd1<- t.test(dose05$len, dose1$len, paired=F)
#.5 vs 2
d05vsd2<-t.test(dose05$len, dose2$len, paired=F)
# 2 vs 1
d2vsd1<- t.test(dose2$len, dose1$len, paired=F)
dose05 <- subset(data, data$dose==.5, select= c(len, supp))
dose1 <- subset(data, data$dose==1, select= c(len, supp))
dose2 <- subset(data, data$dose==2, select= c(len, supp))
#t-tests
#.5 vs 1
t.test(dose05$len, dose1$len, paired=F)
#.5 vs 2
t.test(dose05$len, dose2$len, paired=F)
# 2 vs 1
t.test(dose2$len, dose1$len, paired=F)
dose05 <- subset(data, data$dose==.5)
dose05 <- subset(ToothGrowth, ToothGrowth$dose==.5, select= c(len, supp))
dose05 <- subset(ToothGrowth, ToothGrowth$dose==.5, select= c(len, supp))
dose1 <- subset(ToothGrowth, ToothGrowth$dose==1, select= c(len, supp))
dose2 <- subset(ToothGrowth, ToothGrowth$dose==2, select= c(len, supp))
#t-tests
#.5 vs 1
t.test(dose05$len, dose1$len, paired=F)
#.5 vs 2
t.test(dose05$len, dose2$len, paired=F)
# 2 vs 1
t.test(dose2$len, dose1$len, paired=F)
?boxplot
install.packages("Rvest")
install.packages("rvest")
library(Rvest)
library(rvest)
arts <- html("http://business.camdenchamber.com/list/ql/advertising-media-1")
arts1 <- html_nodes(#mn-members a")
arts1 <- html_nodes(#mn-members a")
arts1 <- html_nodes("#mn-members a")
arts1 <- html_nodes("#mn-members a")
summary(arts)
?html_nodes
arts1 <- html_nodes(arts, "#mn-members a")
install.packeages(selectr)
install.packages(selectr)
install.packages("selectr")
arts1 <- html_nodes(arts, "#mn-members a")
arts1
arts1 <- html_nodes(arts, "#mn-members a")
arts1$a <- html_nodes(arts, "#mn-members a")
rm(list=ls())
arts <- html("http://business.camdenchamber.com/list/ql/advertising-media-1")
arts1$a <- html_nodes(arts, "#mn-members a")
arts1$a <- as.matrix()
arts1 <- NULL
arts1$a <- html_nodes(arts, "#mn-members a")
arts1$a
arts1$address <- html_nodes(".mn-address1, .mn-cityspan  .mn-stspan  .mn-zipspan")
arts1$address <- html_nodes(arts,".mn-address1, .mn-cityspan  .mn-stspan  .mn-zipspan")
arts1$phone <- html_nodes(arts, ".mn-phone")
rm(list=ls())
arts <- html("http://business.camdenchamber.com/list/ql/advertising-media-1")
arts1 <- NULL
arts1$name <- html_nodes(arts, "#mn-members a")
arts1$address <- html_nodes(arts,".mn-address1, .mn-cityspan  .mn-stspan  .mn-zipspan")
arts1$phone <- html_nodes(arts, ".mn-phone")
arts2 <- as.data.frame(arts1)
?XMLNodeSet
arts1$name <- html_text(arts1$name)
arts1$name <- html_nodes(arts, "#mn-members a")
arts1$name <- html_text(arts1$name)
arts1$address <- html_nodes(arts,".mn-address1, .mn-cityspan  .mn-stspan  .mn-zipspan")
arts1$address <- html_text(arts1$address)
arts1$phone <- html_nodes(arts, ".mn-phone")
arts1$phone <- html_text(arts1$phone)
arts2 <- as.data.frame(arts1)
data(mtcars)
head(mtcars)
x <- mtcars$wt
y <- mtcars$mpg
lm(y ~ x)
x <- c(0.8, 0.47, 0.51, 0.73, 0.36, 0.58, 0.57, 0.85, 0.44, 0.42)
y <- c(1.39, 0.72, 1.55, 0.48, 1.19, -1.59, 1.23, -0.65, 1.49, 0.05)
lm(y ~ x)
x <- c(0.8, 0.47, 0.51, 0.73, 0.36, 0.58, 0.57, 0.85, 0.44, 0.42)
y <- c(1.39, 0.72, 1.55, 0.48, 1.19, -1.59, 1.23, -0.65, 1.49, 0.05)
lm(y ~ x)
x <- c(0.61, 0.93, 0.83, 0.35, 0.54, 0.16, 0.91, 0.62, 0.62)
y <- c(0.67, 0.84, 0.6, 0.18, 0.85, 0.47, 1.1, 0.65, 0.36)
# Give a P-value for the two sided hypothesis test of whether
# Î²1 from a linear regression model is 0 or not.
fit <- lm(y ~ x)
summary(fit)$coefficients
data(mtcars)
lm(mtcars$mpg ~ mtcars$weight)
?lm
fit <- lm(mpg ~ wt, data = mtcars)
data(mtcars)
fit <- lm(mpg ~ wt, data = mtcars)
newdata <- data.frame(wt=3)
predict(fit, newdata, interval = ('prediction'))[3]
rm(list=ls()) # clean environment
x <- mtcars$wt
y <- mtcars$mpg
fit <- lm(y ~ x)
c <- 5 # some constant
fit2 <- lm(y ~ I(x + c))
beta0 <- c(fit$coefficients[1], fit2$coefficients[1])
beta1 <- c(fit$coefficients[2], fit2$coefficients[2])
beta0; beta1
rm(list=ls()) # clean environment
y <- mtcars$mpg; x <- mtcars$wt
fitWithIntercept <- lm(y ~ x)
yhat1 <- fit$coefficients[1] + x
se1 <- sum((y - yhat1)^2)
yhat2 <- fit$coefficients[1] + fit$coefficients[2] * x
se2 <- sum((y - yhat2)^2)
ratio <- se2 / se1
data(mtcars)
# About what is the ratio of the the sum of the squared errors
# when comparing a model with just an intercept (denominator)
y <- mtcars$mpg; x <- mtcars$wt; n <- length(y)
fit <- lm(y ~ x - 1)
beta1 <- summary(fit)$coefficients[1]
e <- y - beta1*x
sse1 <- sum(e^2)
# to the model with the intercept and slope (numerator)?
y <- mtcars$mpg; x <- mtcars$wt; n <- length(y)
beta1 <- cor(y, x) * sd(y) / sd(x)
beta0 <- mean(y) - beta1 * mean(x)
e <- y - beta0 - beta1 * x
sse2 <- sum(e^2)
sse2
sse2/sse1
install.packages("AppliedPredictiveModeling")
install.packages("caret")
library(AppliedPredictiveModeling)
library(caret)
data(AlzheimerDisease)
rm(ls=list())
rm(list=ls())
library(AppliedPredictiveModeling)
library(caret)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
trainIndex = createDataPartition(diagnosis, p = 0.50,list=FALSE)
training = adData[trainIndex,]
testing = adData[-trainIndex,]
adData = data.frame(predictors)
trainIndex = createDataPartition(diagnosis,p=0.5,list=FALSE)
training = adData[trainIndex,]
testing = adData[-trainIndex,]
adData = data.frame(diagnosis,predictors)
train = createDataPartition(diagnosis, p = 0.50,list=FALSE)
test = createDataPartition(diagnosis, p = 0.50,list=FALSE)
adData = data.frame(diagnosis,predictors)
trainIndex = createDataPartition(diagnosis, p = 0.50,list=FALSE)
training = adData[trainIndex,]
testing = adData[-trainIndex,]
?createDataPartition
library(caret)
library(installr)
?updateR
updateR()
sessionInfo()
library(AppliedPredictiveModeling)
data(concrete)
data(concrete)
library(caret)
set.seed(1000)
inTrain = createDataPartition(mixtures$CompressiveStrength, p = 3/4)[[1]]
training = mixtures[ inTrain,]
testing = mixtures[-inTrain,]
install.packages("caret")
library(caret)
head(concrete)
setRepositories()
install.packages("caret")
library(caret)
install.packages("SparseM")
install.packages("caret")
library(caret)
trainIndex = createDataPartition(diagnosis,p=0.5,list=FALSE)
updateR()
update.packages()
install.packages("caret")
install.packages("caret")
library(caret)
inTrain = createDataPartition(mixtures$CompressiveStrength, p = 3/4)[[1]]
data(concrete)
library(AppliedPredictiveModels)
library(AppliedPredictiveModeling)
data(concrete)
inTrain = createDataPartition(mixtures$CompressiveStrength, p = 3/4)[[1]]
inTrain
training = mixtures[ inTrain,]
data(mtcars)
fit <- lm(mpg ~ factor(cyl) + wt, data = mtcars)
summary
summary(fit)
x <- c(0.586, 0.166, -0.042, -0.614, 11.72)
y <- c(0.549, -0.026, -0.127, -0.751, 1.344)
# Give the slope dfbeta for the point with the highest hat value.
fit <- lm(y ~ x)
dfbetas(fit)
str(mtcars)
?mtcars
?boxplot
boxplot(mtcars, am ~ mpg)
boxplot(mtcars$mpg)
boxplot(mtcars$mpg, factor=am)
boxplot(mtcars$mpg ~ mtcars$am)
?mtcars
mtcars$am[mtcars$am == 0] <- "automatic"
mtcars$am[mtcars$am == 1] <- "manual"
boxplot(mtcars$mpg ~ mtcars$am, title="MPG by Transmission Type")
boxplot(mtcars$mpg ~ mtcars$am, title="MPG by Transmission Type", ylab="Miles per Gallon")
?boxplot
boxplot(mtcars$mpg ~ mtcars$am, ylab="Miles per Gallon", col = "lightgray")
?mtcars
model2 <- lm(mpg ~ cyl + wt + am, data=mtcars)
summary(model2)
plot(resid(model2))
abline(0,0)
plot(resid(model2), ylab="Residuals")
abline(0, 0)
mean(resid(model2))
plot(model2)
par(mfrow=c(2, 2))
plot(model2)
?coeff
?coefficients
boxplot(mtcars$mpg ~ mtcars$am, ylab="Miles per Gallon", col = "lightgray", quiet=TRUE)
?par
par()
par(mai=c(0.1,0.1,0.1,0.1))
rm(list=ls())
library(AppliedPredictiveModeling)
data(segmentationOriginal)
library(caret)
library(rpart)
library(ggplot2)
library(rattle)
install.packages("rattle")
library(rattle)
library(rattle)
training<-segmentationOriginal[segmentationOriginal$Case=="Train",]
testing<-segmentationOriginal[segmentationOriginal$Case=="Test",]
set.seed(125)
model<-train(Class ~ .,
data = training,
method = "rpart")
fancyRpartPlot(model$finalModel)
install.packages("e1071")
training<-segmentationOriginal[segmentationOriginal$Case=="Train",]
testing<-segmentationOriginal[segmentationOriginal$Case=="Test",]
set.seed(125)
model<-train(Class ~ .,
data = training,
method = "rpart")
fancyRpartPlot(model$finalModel)
install.packages(rpart.plot)
install.packages("rpart.plot")
fancyRpartPlot(model$finalModel)
par(mfrow=c(1, 1))
fancyRpartPlot(model$finalModel)
install.packages("pgmm")
library(pgmm)
data(olive)
olive = olive[,-1]
model<-train(Area ~ ., data=olive, method="rpart")
newdata = as.data.frame(t(colMeans(olive)))
predict(model, newdata)
install.packages("ElemStatLearn")
library(ElemStatLearn)
data(vowel.train)
data(vowel.test)
library(ElemStatLearn)
data(vowel.train)
data(vowel.test)
install.packages("ElemStatLearn")
library(ElemStatLearn)
data(vowel.train)
data(vowel.test)
vowel = rbind(vowel.test,vowel.train)
vowel$y = factor(vowel$y)
vowel.train$y = factor(vowel.train$y)
set.seed(33833)
fit <- randomForest(y~.,data=vowel.train)
imps <- varImp(fit)
order(imps)
install.packages("randomForest")
library(randomForest)
vowel = rbind(vowel.test,vowel.train)
vowel$y = factor(vowel$y)
vowel.train$y = factor(vowel.train$y)
set.seed(33833)
fit <- randomForest(y~.,data=vowel.train)
imps <- varImp(fit)
order(imps)
rm(list=ls()
)
library(caret)
library(ElemStatLearn)
library(kernlab)
library(AppliedPredictiveModeling)
library(randomForest)
library(ggplot2)
library(Metrics)
data(vowel.train)
data(vowel.test)
vowel.train$y<-factor(vowel.train$y)
vowel.test$y<-factor(vowel.test$y)
set.seed(33833)
tr<-trainControl(method="cv", number=5)
model<-train(y ~., method="rf", data=vowel.train, trControl=tr)
plot(varImp(model))
rm(list=ls())
download.file(url = "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv", destfile = "pml-training.csv")
download.file(url = "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv", destfile = "pml-testing.csv")
pmltrain <- read.csv('pml-training.csv')
pmltest <- read.csv('pml-testing.csv')
View(pmltest)
MLtrain <- read.csv('MLtraning.csv')
MLtest <- read.csv('MLtesting.csv')
download.file(url = "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv", destfile = "MLtrain.csv")
download.file(url = "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv", destfile = "MLtest.csv")
MLtrain <- read.csv('MLtran.csv')
MLtest <- read.csv('MLtest.csv')
MLtrain <- read.csv('MLtrain.csv')
NAs <- apply(MLtrain,2,function(x) {sum(is.na(x))})
MLtrain <- training[,which(NAs <  nrow(training)*0.5)]
MLtrain <- MLtrain[,which(NAs <  nrow(MLtrain)*0.5)]
# exclude near zero variance features
NZV <- nearZeroVar(MLtrain)
MLtrain <- MLtrain[, -NZV]
MLtrain <- MLtrain[,which(NAs <  nrow(MLtrain)*0.5)]
NAs <- apply(MLtrain,2,function(x) {sum(is.na(x))})
MLtrain <- MLtrain[,which(NAs <  nrow(MLtrain)*0.5)]
MLtrain <- read.csv('MLtrain.csv')
MLtest <- read.csv('MLtest.csv')
MLtrain <- read.csv('MLtrain.csv')
MLtest <- read.csv('MLtest.csv')
NAs <- apply(MLtrain,2,function(x) {sum(is.na(x))})
MLtrain <- MLtrain[,which(NAs <  nrow(MLtrain)*0.5)]
# exclude near zero variance features
NZV <- nearZeroVar(MLtrain)
MLtrain <- MLtrain[, -NZV]
index <- createDataPartition(y = MLtrain$classe, p=0.6,list=FALSE)
trainPart <- MLtrain[Index,]
testPart <- MLtest[Index,]
library(swirl)
swirl()
library(swirl)
swirl()
cor(gpa_nor,gch_nor)
View(galton)
l_nor <- lm(gch_nor~gpa_nor)
lm(child~parent, galton)
fit <- lm(child~parent, galton)
sqrt(sum(fit$residuals)^2)/(n-2))
sqrt(sum(fit$residuals)^2/(n-2))
sqrt(sum(fit$residuals^2)/(n-2))
summary(fit)$sigma
sqrt(deviance(fit)/(n-2))
mu <- mean(galton$child)
sTot <- d;a
a
dd
dk
info()
skip(
)
sRes <- deviance(sumrE
)
skip()
R^2 <- sRes/sTot
1 - sRes-sTot
1 - sRes/sTot
summary(fit)$r.squared
cor(galton$child,galton$parent)^2
ones <- rep(1, nrow(galton))
lm(child~ones+parent-1,galton)
lm(child~parent,galton)
lm(child~1,galton)
head(trees)
fit <- lm(Volume~Girth+Height+Constant-1,trees)
trees2 <- eliminate("Girth",trees)
head(trees2)
fit2<-lm(Volume~Height+Constant-1,trees2)
lapply(list(fit,fit2),coef)
rm(list=ls())
library(ElemStatLearn)
data(vowel.train)
data(vowel.test)
vowel.test$y <- factor(vowel.test$y)
vowel.train$y <- factor(vowel.train$y)
set.seed(33833)
library(randomForest)
?randomForest
set.seed(3523)
library(AppliedPredictiveModeling)
data(concrete)
inTrain = createDataPartition(concrete$CompressiveStrength, p = 3/4)[[1]]
training = concrete[ inTrain,]
testing = concrete[-inTrain,]
require(e1071)
set.seed(325)
fit<-svm(CompressiveStrength ~., data = training )
pred<-predict(fit, testing)
accuracy(f = pred, x = testing$CompressiveStrength)
update.packages(checkBuilt=TRUE, ask=FALSE
)
install.packagest("shiny")
install.packages("shiny")
library(manipulate)
myPlot <- function(s) {
plot(cars$dist - mean(cars$dist), cars$speed - mean(cars$speed))
abline(0, s)
}
manipulate(myPlot, s = slider(0, 2, step = 0.1))
manipulate(myPlot(s), s = slider(0, 2, step=0.1))
library(rCharts)
install.packages("rCharts")
install.packages("airquality")
library(rCharts)
dTable(airquality, sPaginationType = "full_numbers")
library(devtools)
install_github("ramnathv/rCharts@dev")
install.package("devtools")
install.packages("devtools")
library(devtools)
install_github("ramnathv/rCharts@dev")
library(rCharts)
install.packages("base64enc")
install.packages("devtools")
library(devtools)
install_github("ramnathv/rCharts@dev")
library(rCharts)
dTable(airquality, sPaginationType = "full_numbers")
install_github('slidify', 'ramnathv')
install_github('slidifyLibraries', 'ramnathv')
library(caret)
library("caret", lib.loc="~/R/win-library/3.2")
?update.packages()
update.packages()
y
install.packages("Rlinkedin")
library(Rlinkedin)
install.packages("httpuv")
library(Rlinkedin)
install.packages("httpuv")
library(httpuv)
download.file(https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data)
download.file("https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data")
?download.file
download.file("https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data",destfile=adult)
download.file("https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data",destfile="adult")
adult <- read.csv("https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data")
library(caret)
str(adult)
adult <- read.table("https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data")
createDataPartition(x, list=FALSE, p = 0.6)
library(caret)
install.packages("ggplot2")
library(caret)
install.packages("quantreg")
install.packages("ggplot2")
install.packages("ggplot2")
install.packages("shiny")
library(shiny)
runExample("hello_01")
runExample("01_hello")
runExample("04_mpg")
library(shiny)
?deployApp
deployApp("yield")
getwd()
setwd("C:/Users/Ryan/Documents/R/yield")
deployApp()
library(shinyapps)
setwd("C:/Users/Ryan/Documents/R/yield")
deployApp()
library(slidify)
setwd("C:/Users/Ryan/Documents/R/yield/yieldpitch")
publish(title = 'Estimating Bermuda Grass Yield', 'index.html', host = 'rpubs')
publish_rpubs("Estimating Bermuda Grass Yield", html_file = "index.html")
find.package("RCurl")
.libPaths( "")
publish(title = 'Estimating Bermuda Grass Yield', 'index.html', host = 'rpubs')
find.package("RCurl")
.libPaths( "C:/Users/Ryan/Documents/R/win-library/3.2/")
publish(title = 'Estimating Bermuda Grass Yield', 'index.html', host = 'rpubs')
?publish
publish_rpubs("Estimating Bermuda Grass Yield", html_file = "index.html")
